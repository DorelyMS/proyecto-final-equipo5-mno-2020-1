{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USO DE LA LIBRERÍA LIBMF EN BASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se muestra el uso de la librería libmf con comandos de bash, para lo cual se requiere lo siguiente:\n",
    "1. Clonar el repositorio https://github.com/cjlin1/libmf.git\n",
    "2. Cambiar tu directorio, con el comando `cd`, a donde se encuentre la carpeta \"demo\" (del repositorio anterior) que contiene el archivo \"demo.sh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miuser/repo_libmf/demo\n",
      "/home/miuser/repo_libmf/demo\n",
      "--------------------------------\n",
      "Real-valued matrix factorization\n",
      "--------------------------------\n",
      "iter      tr_rmse      va_rmse          obj\n",
      "   0       2.4800       1.3263   3.2496e+04\n",
      "   1       1.3852       1.0901   1.1317e+04\n",
      "   2       0.8933       1.0364   5.7069e+03\n",
      "   3       0.8004       1.0200   4.9216e+03\n",
      "   4       0.7473       1.0145   4.5285e+03\n",
      "   5       0.7002       1.0070   4.2064e+03\n",
      "   6       0.6543       1.0031   3.9106e+03\n",
      "   7       0.6065       1.0028   3.6208e+03\n",
      "   8       0.5581       1.0032   3.3812e+03\n",
      "   9       0.5096       1.0046   3.1408e+03\n",
      "MAE = 0.7798\n",
      "---------------------------\n",
      "binary matrix factorization\n",
      "---------------------------\n",
      "iter   tr_logloss   va_logloss          obj\n",
      "   0       0.6001       0.8163   2.9870e+03\n",
      "   1       0.6957       0.8163   3.4577e+03\n",
      "   2       0.6814       0.8163   3.3877e+03\n",
      "   3       0.6664       0.8072   3.3163e+03\n",
      "   4       0.6504       0.7995   3.2410e+03\n",
      "   5       0.6315       0.7896   3.1535e+03\n",
      "   6       0.6083       0.7767   3.0468e+03\n",
      "   7       0.5803       0.7561   2.9196e+03\n",
      "   8       0.5454       0.7340   2.7596e+03\n",
      "   9       0.5051       0.7195   2.5759e+03\n",
      "  10       0.4626       0.6951   2.3857e+03\n",
      "  11       0.4157       0.6753   2.1721e+03\n",
      "  12       0.3696       0.6547   1.9650e+03\n",
      "  13       0.3281       0.6410   1.7810e+03\n",
      "  14       0.2900       0.6288   1.6129e+03\n",
      "  15       0.2565       0.6159   1.4661e+03\n",
      "  16       0.2237       0.5998   1.3238e+03\n",
      "  17       0.1976       0.5861   1.2112e+03\n",
      "  18       0.1715       0.5793   1.0986e+03\n",
      "  19       0.1518       0.5762   1.0158e+03\n",
      "ACCURACY = 0.7370\n",
      "-----------------------------------------------------------------\n",
      "one-class matrix factorization using a stochastic gradient method\n",
      "-----------------------------------------------------------------\n",
      "iter   tr_bprloss   va_bprloss          obj\n",
      "   0       0.4449       0.6274   2.3301e+03\n",
      "   1       0.4981       0.5938   2.6198e+03\n",
      "   2       0.5418       0.5692   2.8648e+03\n",
      "   3       0.5089       0.5320   2.7158e+03\n",
      "   4       0.4748       0.5077   2.5588e+03\n",
      "   5       0.4444       0.4910   2.4219e+03\n",
      "   6       0.4047       0.4794   2.2360e+03\n",
      "   7       0.3792       0.4722   2.1203e+03\n",
      "   8       0.3463       0.4244   1.9689e+03\n",
      "   9       0.3185       0.4221   1.8401e+03\n",
      "  10       0.2989       0.4348   1.7522e+03\n",
      "  11       0.2833       0.4337   1.6822e+03\n",
      "  12       0.2724       0.4277   1.6371e+03\n",
      "  13       0.2613       0.4274   1.5894e+03\n",
      "  14       0.2544       0.4274   1.5628e+03\n",
      "  15       0.2499       0.4394   1.5464e+03\n",
      "  16       0.2391       0.4114   1.4973e+03\n",
      "  17       0.2292       0.4271   1.4529e+03\n",
      "  18       0.2248       0.4400   1.4360e+03\n",
      "  19       0.2172       0.4258   1.4032e+03\n",
      "Row-wise MPR = 0.2675\n",
      "Row-wise AUC = 0.7035\n",
      "----------------------------------------------------------------\n",
      "one-class matrix factorization using a coordinate descent method\n",
      "----------------------------------------------------------------\n",
      "iter   tr_sqerror    tr_sqerror+    tr_sqerror-   va_sqerror    va_sqerror+    va_sqerror-          obj\n",
      "   0      76.2547         1.5447        74.7100     565.6007       488.5068        77.0939   1.5152e+02\n",
      "   1      54.0311         1.0794        52.9517     526.2443       470.8935        55.3509   1.0655e+02\n",
      "   2      48.0675         0.9333        47.1343     506.5060       456.9721        49.5339   9.2572e+01\n",
      "   3      45.0470         0.8730        44.1740     493.7466       447.1744        46.5722   8.5755e+01\n",
      "   4      43.0931         0.8323        42.2608     484.5726       439.9154        44.6572   8.1595e+01\n",
      "   5      41.6632         0.8018        40.8614     477.2852       434.0292        43.2560   7.8660e+01\n",
      "   6      40.5349         0.7766        39.7584     471.0943       428.9430        42.1513   7.6374e+01\n",
      "   7      39.5959         0.7544        38.8415     465.6679       424.4350        41.2329   7.4470e+01\n",
      "   8      38.7832         0.7360        38.0472     460.8637       420.4264        40.4372   7.2814e+01\n",
      "   9      38.0603         0.7236        37.3367     456.5794       416.8542        39.7252   7.1334e+01\n",
      "  10      37.4061         0.7200        36.6860     452.7472       413.6743        39.0729   6.9994e+01\n",
      "  11      36.8113         0.7273        36.0840     449.2910       410.8221        38.4689   6.8777e+01\n",
      "  12      36.2759         0.7459        35.5300     446.0790       408.1665        37.9126   6.7679e+01\n",
      "  13      35.8042         0.7744        35.0298     443.0147       405.6049        37.4097   6.6704e+01\n",
      "  14      35.3998         0.8095        34.5903     440.0716       403.1044        36.9672   6.5852e+01\n",
      "  15      35.0605         0.8471        34.2134     437.2577       400.6704        36.5873   6.5116e+01\n",
      "  16      34.7793         0.8832        33.8961     434.5850       398.3181        36.2669   6.4483e+01\n",
      "  17      34.5466         0.9148        33.6319     432.0749       396.0752        35.9996   6.3938e+01\n",
      "  18      34.3528         0.9402        33.4126     429.7432       393.9655        35.7776   6.3465e+01\n",
      "  19      34.1895         0.9592        33.2304     427.5866       391.9937        35.5929   6.3051e+01\n",
      "Row-wise MPR = 0.2030\n",
      "Row-wise AUC = 0.8223\n"
     ]
    }
   ],
   "source": [
    "%cd repo_libmf/demo \n",
    "!pwd #muestra directorio actual\n",
    "!bash demo.sh #se ejecuta el demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el output anterior se puede observar que esta librería puede trabajar con matrices con valores reales, binarios (-1,1) y one-class (puros unos) y que para realizar la factorización de estas matrices se puede usar descenso en gradiente estocástico y por coordenadas mediante una serie de iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se llama a la función \"mf-train\" mandándole la base de entrenamiento con valores reales y con los valores default de los parámetros para que lleve a cabo el entrenamiento. \n",
    "\n",
    "Cuando termina el entrenamiento, se genera el archivo \"model\" con el valor de las columnas de las matrices P y Q, así como los parámetros con los que se entrenó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      tr_rmse          obj\n",
      "   0       1.8803   2.0980e+04\n",
      "   1       0.9877   8.1196e+03\n",
      "   2       0.8672   6.9746e+03\n",
      "   3       0.8122   6.4592e+03\n",
      "   4       0.7846   6.2033e+03\n",
      "   5       0.7660   6.0367e+03\n",
      "   6       0.7512   5.8867e+03\n",
      "   7       0.7406   5.7685e+03\n",
      "   8       0.7317   5.6842e+03\n",
      "   9       0.7239   5.6298e+03\n",
      "  10       0.7184   5.5844e+03\n",
      "  11       0.7079   5.4867e+03\n",
      "  12       0.7062   5.4670e+03\n",
      "  13       0.7008   5.4101e+03\n",
      "  14       0.6972   5.3954e+03\n",
      "  15       0.6903   5.3275e+03\n",
      "  16       0.6875   5.3193e+03\n",
      "  17       0.6815   5.2583e+03\n",
      "  18       0.6756   5.2311e+03\n",
      "  19       0.6708   5.1875e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train real_matrix.tr.txt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un modelo cambiando los valores de los siguientes parámetros:\n",
    "* Coeficiente de regularización L1-norm para la matriz P de 0.05\n",
    "* Coeficiente de regularización L1-norm para la matriz Q de 0.05\n",
    "* Coeficiente de regularización L2-norm para la matriz P de 0.01\n",
    "* Coeficiente de regularización L2-norm para la matriz Q de 0.01\n",
    "\n",
    "Obsérvese que para L1-norm (análogamente para L2-norm) se está asignando el mismo valor para P y Q por lo que al poner sólo -l1 0.05 se entiende que ese mismo valor es para P y Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      tr_rmse          obj\n",
      "   0       1.6993   1.7474e+04\n",
      "   1       0.9916   8.0035e+03\n",
      "   2       0.8619   6.8168e+03\n",
      "   3       0.8051   6.3600e+03\n",
      "   4       0.7636   6.0096e+03\n",
      "   5       0.7437   5.8567e+03\n",
      "   6       0.7266   5.7208e+03\n",
      "   7       0.7101   5.5984e+03\n",
      "   8       0.6944   5.4796e+03\n",
      "   9       0.6797   5.3792e+03\n",
      "  10       0.6656   5.2774e+03\n",
      "  11       0.6520   5.1929e+03\n",
      "  12       0.6373   5.0871e+03\n",
      "  13       0.6163   4.9499e+03\n",
      "  14       0.6063   4.8929e+03\n",
      "  15       0.5942   4.8092e+03\n",
      "  16       0.5868   4.7693e+03\n",
      "  17       0.5734   4.6852e+03\n",
      "  18       0.5613   4.6162e+03\n",
      "  19       0.5498   4.5554e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train -l1 0.05 -l2 0.01 real_matrix.tr.txt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un modelo cambiando los valores de los siguientes parámetros:\n",
    "* Coeficiente de regularización L1-norm para la matriz P de 0.015\n",
    "* Coeficiente de regularización L1-norm para la matriz Q de 0\n",
    "* Coeficiente de regularización L2-norm para la matriz P de 0.01\n",
    "* Coeficiente de regularización L2-norm para la matriz Q de 0.005\n",
    "\n",
    "En este caso para L1-norm (análogamente para L2-norm) se están asignando diferentes valores a la matriz P y Q, por lo que al poner -l1 es necesario separar con una coma el valor para cada matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      tr_rmse          obj\n",
      "   0       1.9517   1.9523e+04\n",
      "   1       0.9772   5.2570e+03\n",
      "   2       0.8488   4.0884e+03\n",
      "   3       0.7926   3.6306e+03\n",
      "   4       0.7586   3.3701e+03\n",
      "   5       0.7408   3.2366e+03\n",
      "   6       0.7194   3.0835e+03\n",
      "   7       0.7061   2.9913e+03\n",
      "   8       0.6924   2.8955e+03\n",
      "   9       0.6789   2.8048e+03\n",
      "  10       0.6650   2.7121e+03\n",
      "  11       0.6519   2.6306e+03\n",
      "  12       0.6384   2.5439e+03\n",
      "  13       0.6223   2.4454e+03\n",
      "  14       0.6102   2.3731e+03\n",
      "  15       0.5974   2.2985e+03\n",
      "  16       0.5838   2.2190e+03\n",
      "  17       0.5704   2.1448e+03\n",
      "  18       0.5572   2.0718e+03\n",
      "  19       0.5445   2.0047e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train -l1 0.015,0 -l2 0.01,0.005 real_matrix.tr.txt model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se llama a la función \"mf-train\" pero ahora mandándole la base de entrenamiento con valores binarios (-1,1) con los siguientes parámetros para que lleve a cabo el entrenamiento: \n",
    "\n",
    "* Función de pérdida: logarithmic error (-f 5)\n",
    "* Coeficiente de regularización L1-norm para P: 0 (-l1 0)\n",
    "* Coeficiente de regularización L1-norm para Q: 0.02 (-l1 0.02)\n",
    "* Número de factores latentes: 100 (-k 100)\n",
    "* Número de interaciones: 30 (-t 30)\n",
    "* Tasa de aprendizaje: 0.02 (-r 0.02)\n",
    "* Número de threads: 4 (-s 4)\n",
    "\n",
    "De igual forma, cuando termina el entrenamiento, se genera el archivo \"model\" con el valor de las columnas de las matrices P y Q, así como los parámetros con los que se entrenó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   tr_logloss          obj\n",
      "   0       0.6994   4.1035e+03\n",
      "   1       0.6946   4.0091e+03\n",
      "   2       0.6915   3.9370e+03\n",
      "   3       0.6891   3.8787e+03\n",
      "   4       0.6873   3.8317e+03\n",
      "   5       0.6859   3.7931e+03\n",
      "   6       0.6848   3.7612e+03\n",
      "   7       0.6840   3.7349e+03\n",
      "   8       0.6833   3.7123e+03\n",
      "   9       0.6828   3.6930e+03\n",
      "  10       0.6824   3.6763e+03\n",
      "  11       0.6820   3.6618e+03\n",
      "  12       0.6818   3.6490e+03\n",
      "  13       0.6815   3.6378e+03\n",
      "  14       0.6813   3.6277e+03\n",
      "  15       0.6811   3.6188e+03\n",
      "  16       0.6809   3.6106e+03\n",
      "  17       0.6808   3.6033e+03\n",
      "  18       0.6807   3.5964e+03\n",
      "  19       0.6805   3.5898e+03\n",
      "  20       0.6805   3.5848e+03\n",
      "  21       0.6805   3.5796e+03\n",
      "  22       0.6804   3.5747e+03\n",
      "  23       0.6803   3.5703e+03\n",
      "  24       0.6803   3.5663e+03\n",
      "  25       0.6802   3.5624e+03\n",
      "  26       0.6802   3.5588e+03\n",
      "  27       0.6802   3.5554e+03\n",
      "  28       0.6801   3.5522e+03\n",
      "  29       0.6801   3.5493e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train -f 5 -l1 0,0.02 -k 100 -t 30 -r 0.02 -s 4 binary_matrix.tr.txt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un modelo cambiando el siguiente parámetro:\n",
    "* Número de folds para cross validation: 5 (-v 5)\n",
    "\n",
    "En la que se muestra que el promedio de la raiz de los errores cuadráticos medios de los cinco folds fue de 1.4781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold      rmse\n",
      "   0    1.4036\n",
      "   1    1.4243\n",
      "   2    1.5067\n",
      "   3    1.5453\n",
      "   4    1.5107\n",
      "==============\n",
      " avg    1.4781\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train -v 5 real_matrix.tr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un modelo cambiando el siguiente parámetro:\n",
    "* Función de pérdida: generalized KL-divergence (-f 2) la cual requiere la factorización no negativa (--nmf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter       tr_gkl          obj\n",
      "   0       1.0041   8.0817e+03\n",
      "   1       0.2079   3.8743e+03\n",
      "   2       0.1760   3.6688e+03\n",
      "   3       0.1574   3.5462e+03\n",
      "   4       0.1455   3.4374e+03\n",
      "   5       0.1376   3.3963e+03\n",
      "   6       0.1312   3.3192e+03\n",
      "   7       0.1278   3.2970e+03\n",
      "   8       0.1244   3.2748e+03\n",
      "   9       0.1207   3.2399e+03\n",
      "  10       0.1186   3.2146e+03\n",
      "  11       0.1162   3.1914e+03\n",
      "  12       0.1140   3.1618e+03\n",
      "  13       0.1137   3.1662e+03\n",
      "  14       0.1117   3.1564e+03\n",
      "  15       0.1100   3.1345e+03\n",
      "  16       0.1087   3.1158e+03\n",
      "  17       0.1089   3.1297e+03\n",
      "  18       0.1063   3.1198e+03\n",
      "  19       0.1051   3.1019e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train -f 2 --nmf real_matrix.tr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo en el que no se muestran las salidas (quiet mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/miuser/repo_libmf/mf-train --quiet real_matrix.tr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de perform disk-level training (will create a buffer file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      tr_rmse          obj\n",
      "   0       1.7957   1.9406e+04\n",
      "   1       1.4365   1.3634e+04\n",
      "   2       0.9624   7.8187e+03\n",
      "   3       0.8256   6.5570e+03\n",
      "   4       0.7757   6.1244e+03\n",
      "   5       0.7559   5.9153e+03\n",
      "   6       0.7438   5.8308e+03\n",
      "   7       0.7250   5.6852e+03\n",
      "   8       0.7140   5.5756e+03\n",
      "   9       0.7095   5.5185e+03\n",
      "  10       0.7095   5.5048e+03\n",
      "  11       0.7024   5.4265e+03\n",
      "  12       0.6977   5.4181e+03\n",
      "  13       0.6928   5.3306e+03\n",
      "  14       0.6888   5.3220e+03\n",
      "  15       0.6886   5.3197e+03\n",
      "  16       0.6826   5.2786e+03\n",
      "  17       0.6781   5.2334e+03\n",
      "  18       0.6692   5.1885e+03\n",
      "  19       0.6652   5.1510e+03\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-train --disk real_matrix.tr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se llama a la función \"mf-predict\" mandándole la base de prueba con valores reales y el modelo entrenado para que lleve a cabo las predicciones y calcule el error con el método por default (root mean square error).\n",
    "\n",
    "Cuando termina de hacer las predicciones, se genera el archivo \"output\" con el valor de las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.0089\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-predict real_matrix.te.txt model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se llama a la función \"mf-predict\" mandándole la base de prueba con valores reales y el modelo entrenado para que lleve a cabo las predicciones y calcule el error absoluto medio (-e 1).\n",
    "\n",
    "De igual forma, cuando termina de hacer las predicciones, se genera el archivo \"output\" con el valor de las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.7840\n"
     ]
    }
   ],
   "source": [
    "!/home/miuser/repo_libmf/mf-predict -e 1 real_matrix.te.txt model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
