{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activate intelisense functionality\n",
    "#%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /home/miuser/.local/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/miuser/.local/lib/python3.6/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/miuser/.local/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/miuser/.local/lib/python3.6/site-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: h5py in /home/miuser/.local/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/miuser/.local/lib/python3.6/site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "#from keras.models import Model\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/jupyter/datasets/netflix_complete_cleaned.txt',sep=' ', header = None, names = ['Cust_Id','Movie_Id','Rating'], usecols = [0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un resumen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100480507, 3)\n",
      "Dataset types:\n",
      "Cust_Id       int64\n",
      "Movie_Id      int64\n",
      "Rating      float64\n",
      "dtype: object\n",
      "Summary statistics from dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_Id</th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.004805e+08</td>\n",
       "      <td>1.004805e+08</td>\n",
       "      <td>1.004805e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.322489e+06</td>\n",
       "      <td>9.070915e+03</td>\n",
       "      <td>3.604290e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.645368e+05</td>\n",
       "      <td>5.131891e+03</td>\n",
       "      <td>1.085219e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.611980e+05</td>\n",
       "      <td>4.677000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.319012e+06</td>\n",
       "      <td>9.051000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.984455e+06</td>\n",
       "      <td>1.363500e+04</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.649429e+06</td>\n",
       "      <td>1.777000e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cust_Id      Movie_Id        Rating\n",
       "count  1.004805e+08  1.004805e+08  1.004805e+08\n",
       "mean   1.322489e+06  9.070915e+03  3.604290e+00\n",
       "std    7.645368e+05  5.131891e+03  1.085219e+00\n",
       "min    6.000000e+00  1.000000e+00  1.000000e+00\n",
       "25%    6.611980e+05  4.677000e+03  3.000000e+00\n",
       "50%    1.319012e+06  9.051000e+03  4.000000e+00\n",
       "75%    1.984455e+06  1.363500e+04  4.000000e+00\n",
       "max    2.649429e+06  1.777000e+04  5.000000e+00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataset shape: {}'.format(df.shape))\n",
    "print('Dataset types:')\n",
    "print(df.dtypes)\n",
    "print('Summary statistics from dataset:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos peliculas y usuarios con pocas evaluaciones para reducir el tama√±o del dataset y mejorar predicciones. (Prune dataset)\n",
    "Filtramos deacuerdo al percentil 80 \n",
    "Movie minimum times of review: 1799.0\n",
    "Customer minimum times of review: 52.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie minimum times of review: 12304.0\n",
      "Customer minimum times of review: 541.0\n"
     ]
    }
   ],
   "source": [
    "#f = ['count','mean']\n",
    "\n",
    "#df_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\n",
    "#df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "#movie_benchmark = round(df_movie_summary['count'].quantile(0.9),0)\n",
    "#drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "#print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "\n",
    "#df_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\n",
    "#df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "#cust_benchmark = round(df_cust_summary['count'].quantile(0.9),0)\n",
    "#drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "\n",
    "#print('Customer minimum times of review: {}'.format(cust_benchmark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings unfiltered:\t(100480507, 3)\n",
      "Shape User-Ratings filtered:\t(90723839, 3)\n"
     ]
    }
   ],
   "source": [
    "# Filter sparse movies\n",
    "min_movie_ratings = 1799\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 52\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un shuffle del dataframe y lo dividimos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100480507\n",
      "80384406\n",
      "20096101\n"
     ]
    }
   ],
   "source": [
    "random.seed(28882)\n",
    "#random shuffle dataset\n",
    "df2=df.sample(frac=1).reset_index(drop=True)\n",
    "print(len(df2))\n",
    "\n",
    "#dividimos dataset en train y test\n",
    "n=round(len(df2)*.8) #tamano de muestra de entrenamiento 80% de los datos\n",
    "df_train=df2[-n:]\n",
    "print(len(df_train)) # de valores en el dataset de entrenamiento\n",
    "df_test=df2[:-n] # de valores en dataset de prueba\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (80384406, 3)\n",
      "-Dataset examples-\n",
      "           Cust_Id  Movie_Id  Rating\n",
      "0          1488844         1     3.0\n",
      "5000000     501954       996     2.0\n",
      "10000000    404654      1962     5.0\n",
      "15000000    886608      2876     2.0\n",
      "20000000   1193835      3825     2.0\n",
      "25000000   1899206      4661     3.0\n",
      "30000000    154804      5496     4.0\n",
      "35000000   2078749      6274     5.0\n",
      "40000000    450763      7057     5.0\n",
      "45000000    102092      7991     3.0\n",
      "50000000    220298      9023     5.0\n",
      "55000000    550530     10042     5.0\n",
      "60000000    222570     11038     3.0\n",
      "65000000   1273080     11875     5.0\n",
      "70000000   2026970     12676     5.0\n",
      "75000000    506044     13582     4.0\n",
      "80000000    353605     14453     2.0\n",
      "85000000    664606     15116     3.0\n",
      "90000000   2213715     16008     3.0\n",
      "95000000   1589401     16879     5.0\n",
      "100000000  2314006     17627     4.0\n"
     ]
    }
   ],
   "source": [
    "df_train.to_csv(r'../datasets/netflix_train.txt',header=False,sep = ' ',index=False)\n",
    "print('Full dataset shape: {}'.format(df_train.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (20096101, 3)\n",
      "-Dataset examples-\n",
      "           Cust_Id  Movie_Id  Rating\n",
      "0          1488844         1     3.0\n",
      "5000000     501954       996     2.0\n",
      "10000000    404654      1962     5.0\n",
      "15000000    886608      2876     2.0\n",
      "20000000   1193835      3825     2.0\n",
      "25000000   1899206      4661     3.0\n",
      "30000000    154804      5496     4.0\n",
      "35000000   2078749      6274     5.0\n",
      "40000000    450763      7057     5.0\n",
      "45000000    102092      7991     3.0\n",
      "50000000    220298      9023     5.0\n",
      "55000000    550530     10042     5.0\n",
      "60000000    222570     11038     3.0\n",
      "65000000   1273080     11875     5.0\n",
      "70000000   2026970     12676     5.0\n",
      "75000000    506044     13582     4.0\n",
      "80000000    353605     14453     2.0\n",
      "85000000    664606     15116     3.0\n",
      "90000000   2213715     16008     3.0\n",
      "95000000   1589401     16879     5.0\n",
      "100000000  2314006     17627     4.0\n"
     ]
    }
   ],
   "source": [
    "df_test.to_csv(r'../datasets/netflix_test.txt',header=False,sep = ' ',index=False)\n",
    "print('Full dataset shape: {}'.format(df_test.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertar en libreria libmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miuser/jupyter/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
